# FPN(Feature Pyramid Networks for Object Detection)

###背景

传统空间金字塔算法用于处理多尺度图像以得到尺度不变性，但是在深度神经网络中，往往处于性能（速度）的考虑摒弃空间金字塔（如fast rcnn网络中用单一图像尺度+多尺度anchor 而不用sppnet中的多尺度）。但是金字塔模型依旧是非常有效的，在imageNet和COCO比赛中，很多算法模型在测试阶段利用多尺度图像，来得到更好的结果。（尤其在detection中对于小物体非常有效）。

###目的
本文希望在深度神经网络中，通过top-down的方式构建“特征金字塔”。因为在深度神经网络的前馈过程中，经过每一层卷积产生的feature map就是类似于一个多尺度的金字塔，它的特点是，越靠近down的feature map越大（分辨率高）但是特征不够抽象，越靠近top的feature map越小（分辨率小）但是特征很抽象。作者希望能够结合两者的优点。

如下图所示：

![fpn](https://github.com/xiangcong/xiangcong.github.io/blob/master/images/fpn.png?raw=true)

### 如何构建feature Pyramid？

以resnet为例，feature map大小相同的视为同一个stage，
把每stage最后一个feature map作为该stage的代表。
故有4个feature pyramid（C2, C3, C4, C5），相对输入图像的stride分别为4，8，16，32。不取C1，因为C1太大浪费memory。

自上而下构建侧（lateral）连接，如下图所示

![fpn2](https://github.com/xiangcong/xiangcong.github.io/blob/master/images/fpn2.png?raw=true)

上一层feature map 上采样（用deconv, stride 2， 另外channel数也要减少）后与下一层feature map相加，在加上一个3*3的卷积(channel 统一为256)构成最终的feature map。-> (P2, P3, P4, P5)大小不同，厚度相同

上一层：更抽象，更具语义信息
下一层：分辨率更大，位置信息更好

### 应用
#### 对于RPN

将最后一层卷积层（network head）替换为FPN，将3x3的卷积和两个1x1的卷积应用到feature pyramid的每一层（因为feature pyramid中每一层的尺度不同，这样就不用多尺度的anchor了）

Formally, we define the an- chors to have areas of {32^2 , 64^2 , 128^2 , 256^2 , 512^2 } pixels on {P2, P3, P4, P5, P6} respectively.

we also use anchors of multiple aspect ratios {1:2, 1:1, 2:1} at each level. So in total there are 15 anchors over the pyramid

即总共3*5=15个anchor。 3x3的卷积层参数是共享的。

### 对于Fast RCNN

根据公式 k = k0 + log2(sqrt(wh)/224)选择对应的pyramid level


